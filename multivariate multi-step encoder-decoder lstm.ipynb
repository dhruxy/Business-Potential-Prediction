{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f7a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate multi-step encoder-decoder lstm \n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdaf6177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6d300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define input sequence\n",
    "# in_seq1 = array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "# in_seq2 = array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "# out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# # convert to [rows, columns] structure\n",
    "# in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "# in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "# out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# # horizontally stack columns\n",
    "# dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12963551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1543245  0.11970796 0.17823648 ... 0.46352725 1.64151026 0.30708925]\n",
      " [0.12290076 0.11983117 0.16549748 ... 0.57131545 1.64993684 0.45160385]\n",
      " [0.12758278 0.11297011 0.19075444 ... 0.64402526 2.11044938 0.44806313]\n",
      " ...\n",
      " [0.37375369 0.34499689 0.40026859 ... 1.20782415 1.77394841 0.81705893]\n",
      " [0.3336417  0.30050302 0.36040647 ... 1.1479989  1.64021404 0.75481252]\n",
      " [0.24217588 0.21514682 0.33592286 ... 0.76868481 1.48927726 0.54231719]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dasatest.csv')\n",
    "# print(df.head())\n",
    "df['Month'] = pd.to_datetime(df.Month , format = '%d/%m/%Y')\n",
    "data = df.drop(['Month'], axis=1)\n",
    "data.index = df.Month\n",
    "# print(df.head())\n",
    "cols = data.columns\n",
    "dataset = data[cols].astype(float)\n",
    "dataset = np.array(dataset)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10982e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "# scaler = scaler.fit(dataset)\n",
    "# dataset_scaled = scaler.transform(dataset)\n",
    "# print(dataset_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04866526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 36, 3915) (22, 15, 3915)\n"
     ]
    }
   ],
   "source": [
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 36, 15\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "n_features = X.shape[2]\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e34fc9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 50)                793200    \n",
      "                                                                 \n",
      " repeat_vector_8 (RepeatVect  (None, 15, 50)           0         \n",
      " or)                                                             \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 15, 36)            12528     \n",
      "                                                                 \n",
      " time_distributed_8 (TimeDis  (None, 15, 3915)         144855    \n",
      " tributed)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 950,583\n",
      "Trainable params: 950,583\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(LSTM(36, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mape')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cbee2fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 7s 7s/step - loss: 438197.0625 - val_loss: 647042.0000\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 468427.3125 - val_loss: 710892.5625\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 499383.9375 - val_loss: 727502.1250\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 504174.7500 - val_loss: 765191.8125\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 469285.4688 - val_loss: 810023.8125\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 492570.7188 - val_loss: 831160.4375\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 486113.4062 - val_loss: 840234.8125\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 486700.8125 - val_loss: 859942.3125\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 309ms/step - loss: 506471.0625 - val_loss: 882963.8750\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 485532.6562 - val_loss: 907507.1875\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 492304.6875 - val_loss: 928081.8750\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 505097.2500 - val_loss: 940977.8125\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 499643.4062 - val_loss: 931429.6250\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 501465.2500 - val_loss: 940027.5000\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 498058.4688 - val_loss: 947214.1250\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 489023.6250 - val_loss: 971284.6875\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 491647.0312 - val_loss: 996042.8750\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 502374.2500 - val_loss: 988252.6250\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 498571.8125 - val_loss: 989177.6875\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 494988.6562 - val_loss: 1000857.8750\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 509425.9375 - val_loss: 1005538.6250\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 503090.9375 - val_loss: 1005991.6875\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 503179.8750 - val_loss: 1006913.1250\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 512734.1250 - val_loss: 994043.3125\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 502391.2812 - val_loss: 999754.8750\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 494622.1875 - val_loss: 1016257.1875\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 311ms/step - loss: 523217.7188 - val_loss: 1016723.5000\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 1s 555ms/step - loss: 490203.9375 - val_loss: 1020848.1875\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 495484.8125 - val_loss: 1031161.1875\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 527307.4375 - val_loss: 1026123.5000\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 504692.2500 - val_loss: 1038493.3125\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 500732.0625 - val_loss: 1030875.8125\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 493973.8125 - val_loss: 1023136.3750\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 490251.7812 - val_loss: 1014750.8750\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 489790.8750 - val_loss: 1022274.0000\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 491802.6562 - val_loss: 1013822.5000\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 491567.1250 - val_loss: 1022885.6250\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 503122.4062 - val_loss: 1028185.6875\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 509310.8125 - val_loss: 1027995.8125\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 482403.5938 - val_loss: 1023168.3750\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 482790.5938 - val_loss: 1026243.8125\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 512812.2500 - val_loss: 1023756.3750\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 501754.4688 - val_loss: 1020733.1875\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 491009.0000 - val_loss: 1027960.6250\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 505747.6562 - val_loss: 1020578.6250\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 499423.4062 - val_loss: 1016108.8750\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 478959.6875 - val_loss: 1009379.0000\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 489419.3438 - val_loss: 998643.1875\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 285ms/step - loss: 505636.3438 - val_loss: 1005482.8125\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 509778.1250 - val_loss: 1012167.3750\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 494817.5938 - val_loss: 1025757.1250\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 467243.8750 - val_loss: 1022262.1875\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 475328.5938 - val_loss: 1028248.1250\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 513649.6562 - val_loss: 1018641.1875\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 500205.0625 - val_loss: 1012798.1250\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 472364.6562 - val_loss: 1022594.3750\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 503306.4062 - val_loss: 1028813.8750\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 512130.7188 - val_loss: 1029525.3750\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 490291.5000 - val_loss: 1021646.8125\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 505963.7500 - val_loss: 1018532.8750\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 503246.4062 - val_loss: 1011677.1875\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 470116.9375 - val_loss: 1022065.8125\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 507057.3438 - val_loss: 1019416.1875\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 496641.0000 - val_loss: 1023114.0000\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 474827.7812 - val_loss: 1025890.1875\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 486278.2500 - val_loss: 1021655.1250\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 499198.9375 - val_loss: 1023375.8750\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 486981.5625 - val_loss: 1025567.3750\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 472852.2812 - val_loss: 1018547.1875\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 466000.6875 - val_loss: 1018201.5000\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 465049.2812 - val_loss: 1018928.3125\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 476948.3125 - val_loss: 1006946.6250\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 473999.2812 - val_loss: 1000648.8750\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 449662.0938 - val_loss: 994277.6250\n",
      "Epoch 75/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 203ms/step - loss: 459206.3125 - val_loss: 1011292.8750\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 467738.1562 - val_loss: 1020957.6250\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 444043.1875 - val_loss: 1026112.1875\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 439854.2188 - val_loss: 1023422.5000\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 486230.2500 - val_loss: 999040.6250\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 451795.4062 - val_loss: 998585.6875\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 372ms/step - loss: 459798.1875 - val_loss: 992655.3750\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 314ms/step - loss: 468816.2812 - val_loss: 1009155.6250\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 472915.3125 - val_loss: 1032536.8125\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 470372.7188 - val_loss: 1036138.6875\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 447102.6562 - val_loss: 1026146.1875\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 451982.0938 - val_loss: 1020302.5000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 484795.4375 - val_loss: 1023275.8125\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 481043.6562 - val_loss: 1024908.1250\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 452583.9062 - val_loss: 1019880.6250\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 470438.7812 - val_loss: 1023395.0000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 486054.8750 - val_loss: 1011937.6250\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 304ms/step - loss: 471041.5938 - val_loss: 1014435.8125\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 471896.5625 - val_loss: 1010540.6875\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 470994.5312 - val_loss: 993422.5000\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 461325.5625 - val_loss: 1010354.1250\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 469035.4688 - val_loss: 1020211.6250\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 474380.2812 - val_loss: 1011770.0000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 469213.4688 - val_loss: 1004008.8125\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 475309.9375 - val_loss: 992933.8750\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 462273.3125 - val_loss: 991437.3125\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 445843.5625 - val_loss: 1014393.8125\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 467134.3438 - val_loss: 1022136.1875\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 477688.1250 - val_loss: 995767.6875\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 461344.6875 - val_loss: 998750.0000\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 453038.1562 - val_loss: 1021672.1250\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 466177.2188 - val_loss: 1019542.5000\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 469243.1875 - val_loss: 1021763.8125\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 461533.0000 - val_loss: 1012887.1250\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 457556.1875 - val_loss: 998593.8125\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 455246.6875 - val_loss: 1008430.8750\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 456462.3125 - val_loss: 1020266.3750\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 468665.1875 - val_loss: 1002344.3125\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 446054.8438 - val_loss: 1000551.1250\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 449313.2500 - val_loss: 1011918.0000\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 456691.9062 - val_loss: 992532.1875\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 457304.5312 - val_loss: 989206.3750\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 450185.7812 - val_loss: 1007763.8125\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 449557.2188 - val_loss: 1017031.1250\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 468602.4062 - val_loss: 1028228.3750\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 466430.0000 - val_loss: 1014076.6875\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 458340.1875 - val_loss: 986473.1875\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 459312.9375 - val_loss: 995870.0000\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 472057.7188 - val_loss: 1017280.1875\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 456140.9062 - val_loss: 1009836.8750\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 456011.3125 - val_loss: 1011748.3750\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 452377.5625 - val_loss: 1021422.1875\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 209ms/step - loss: 479246.3125 - val_loss: 1014725.6250\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 475203.8438 - val_loss: 1009531.1875\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 455274.0312 - val_loss: 1013119.6875\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 478369.0000 - val_loss: 1008261.1875\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 472490.7812 - val_loss: 1009800.3125\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 475243.9688 - val_loss: 1011031.8750\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 455131.4062 - val_loss: 990580.8125\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 436574.6250 - val_loss: 998337.6875\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 454360.2812 - val_loss: 999514.8125\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 453717.7188 - val_loss: 1005836.8125\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 449836.6250 - val_loss: 1017954.3750\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 467326.6250 - val_loss: 1009241.8750\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 337ms/step - loss: 472870.1562 - val_loss: 1010521.3750\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 451591.6875 - val_loss: 1009467.8125\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 438491.0938 - val_loss: 1011138.8750\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 456485.2188 - val_loss: 1003813.0000\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 448735.7500 - val_loss: 1000510.8750\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 439320.1875 - val_loss: 994493.0000\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 448173.2812 - val_loss: 980048.8750\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 438215.1250 - val_loss: 989832.3750\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 436748.5625 - val_loss: 1009414.8125\n",
      "Epoch 148/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step - loss: 447769.5938 - val_loss: 1016957.1875\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 435790.7500 - val_loss: 1006120.8750\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 419360.7500 - val_loss: 994137.8125\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 428483.9375 - val_loss: 988401.1875\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 426295.9688 - val_loss: 993680.0000\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 432297.5000 - val_loss: 986889.1250\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 429691.3750 - val_loss: 997168.3125\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 428933.4688 - val_loss: 1009346.0000\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 415198.0000 - val_loss: 1001421.0000\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 407503.1250 - val_loss: 983859.5000\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 403004.7812 - val_loss: 998024.0000\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 436550.0312 - val_loss: 1014120.6250\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 429166.3750 - val_loss: 1017414.0000\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 409076.2500 - val_loss: 1014665.5000\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 412531.3125 - val_loss: 992466.1250\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 407228.5312 - val_loss: 990141.0000\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 409990.0312 - val_loss: 987395.0000\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 406422.8438 - val_loss: 983848.1875\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 400831.7188 - val_loss: 983915.0000\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 405759.6250 - val_loss: 985457.6250\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 413623.5312 - val_loss: 980634.3750\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 364ms/step - loss: 399585.4062 - val_loss: 980759.3750\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 404904.2500 - val_loss: 991624.3125\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 429858.6250 - val_loss: 1001579.3125\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 423457.8438 - val_loss: 997491.6250\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 418024.8125 - val_loss: 988804.1875\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 429028.9375 - val_loss: 973883.3125\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 416400.3750 - val_loss: 989502.1875\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 435360.9062 - val_loss: 992597.3750\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 429607.8438 - val_loss: 994129.5000\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 426682.4375 - val_loss: 989654.8750\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 424501.4375 - val_loss: 995778.6250\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 433826.6562 - val_loss: 992550.1250\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 431214.0625 - val_loss: 981302.1875\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 427211.4062 - val_loss: 966236.6250\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 437077.4375 - val_loss: 985319.6875\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 435112.9688 - val_loss: 1002552.3750\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 445365.1875 - val_loss: 984032.3750\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 446025.7812 - val_loss: 955035.8750\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 428386.5000 - val_loss: 978086.1250\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 421235.4062 - val_loss: 996311.3750\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 435719.0625 - val_loss: 997523.8750\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 429227.0312 - val_loss: 985669.3750\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 425286.8750 - val_loss: 974959.8750\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 427578.4375 - val_loss: 975493.3125\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 441489.7812 - val_loss: 968348.8125\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 432196.5312 - val_loss: 950297.6875\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 434878.1562 - val_loss: 966253.6250\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 426652.7812 - val_loss: 992240.6250\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 419842.7500 - val_loss: 992336.8750\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 428330.4375 - val_loss: 969880.8750\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 418461.6250 - val_loss: 964501.3750\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 417384.0312 - val_loss: 973392.8125\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 441427.0938 - val_loss: 973806.8750\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 433779.2500 - val_loss: 967935.6875\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 415938.1250 - val_loss: 983924.8125\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 418630.1562 - val_loss: 967033.1250\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 411034.4375 - val_loss: 944468.6875\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 418870.1875 - val_loss: 947138.6875\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 430147.6250 - val_loss: 963887.8750\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 418548.0312 - val_loss: 968987.5000\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 419823.0938 - val_loss: 964317.1875\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 430213.2812 - val_loss: 972276.1250\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 414565.2188 - val_loss: 969483.1250\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 408507.4375 - val_loss: 961899.1875\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 421653.6875 - val_loss: 946946.1875\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 412805.4375 - val_loss: 939188.6250\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 385378.9062 - val_loss: 962541.6250\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 413688.3438 - val_loss: 967854.8750\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 421179.6562 - val_loss: 952737.1875\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 419448.4688 - val_loss: 964289.1875\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 422345.6562 - val_loss: 974736.3125\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 418142.1875 - val_loss: 968356.6250\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 427017.0312 - val_loss: 937879.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 426516.9062 - val_loss: 934355.1875\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 423322.6875 - val_loss: 951241.8125\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 421531.4688 - val_loss: 943079.1250\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 415064.0000 - val_loss: 943045.8125\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 421012.2188 - val_loss: 963591.1875\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 424464.6562 - val_loss: 964743.3750\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 414632.2188 - val_loss: 937171.3750\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 404052.0625 - val_loss: 921742.6250\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 415419.0000 - val_loss: 935445.1250\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 433513.0312 - val_loss: 950131.0000\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 420649.1875 - val_loss: 941047.1250\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 406869.5625 - val_loss: 947881.1875\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 428832.5312 - val_loss: 961595.3750\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 435284.0312 - val_loss: 955970.8750\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 418264.2812 - val_loss: 948063.1250\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 409322.3438 - val_loss: 941176.1250\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 423537.3125 - val_loss: 953076.6250\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 430715.1875 - val_loss: 958640.8750\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 413018.1875 - val_loss: 943019.8125\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 418644.2188 - val_loss: 926184.1250\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 404869.5625 - val_loss: 942922.8125\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 417960.4375 - val_loss: 955219.1250\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 409079.0625 - val_loss: 956213.8750\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 393575.0312 - val_loss: 944995.3125\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 403103.0000 - val_loss: 945383.1250\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 406140.1875 - val_loss: 934244.6250\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 397079.0938 - val_loss: 950162.0000\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 420788.0312 - val_loss: 951871.8125\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 405865.0000 - val_loss: 942794.1250\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 402667.2812 - val_loss: 946192.1250\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 429511.7188 - val_loss: 932706.6875\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 416016.2500 - val_loss: 917091.8125\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 388444.3125 - val_loss: 929682.3750\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 419533.4688 - val_loss: 932973.8750\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 407572.5312 - val_loss: 940985.1875\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 401301.2812 - val_loss: 960043.8750\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 405535.9688 - val_loss: 973524.6875\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 405310.1562 - val_loss: 955927.6250\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 405703.8438 - val_loss: 936179.8125\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 399768.2812 - val_loss: 933029.3125\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 395706.0938 - val_loss: 933628.6875\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 384319.8438 - val_loss: 942141.8750\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 405593.3438 - val_loss: 932945.6875\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 393985.1250 - val_loss: 937035.1250\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 395920.9375 - val_loss: 941353.5000\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 407490.1875 - val_loss: 935844.1875\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 402506.4062 - val_loss: 948540.3750\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 400244.0625 - val_loss: 943898.3750\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 413469.6875 - val_loss: 937315.6250\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 396608.0312 - val_loss: 938570.8750\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 391956.8438 - val_loss: 927813.1250\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 405787.4375 - val_loss: 927868.1875\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 405202.3438 - val_loss: 945742.8125\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 405866.1875 - val_loss: 941424.8750\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 393811.0625 - val_loss: 922189.1250\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 390098.4688 - val_loss: 935047.8750\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 397996.3125 - val_loss: 953810.3750\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 399189.6562 - val_loss: 932923.0000\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 397370.6562 - val_loss: 918072.8750\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 397114.9375 - val_loss: 932551.8125\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 388011.9375 - val_loss: 939641.8125\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 401690.0938 - val_loss: 933105.6875\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 399825.3438 - val_loss: 906023.8125\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 390063.0000 - val_loss: 901258.1250\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 376012.1875 - val_loss: 928350.1250\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 382924.4688 - val_loss: 936834.8750\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 373619.9375 - val_loss: 915706.3750\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 367430.1875 - val_loss: 908890.6875\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 367278.3125 - val_loss: 916715.8750\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 364101.0625 - val_loss: 915476.6250\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 361604.2500 - val_loss: 918327.8750\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 362845.2812 - val_loss: 914671.6250\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 376629.0625 - val_loss: 926119.1875\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 372013.6562 - val_loss: 919686.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 368744.9062 - val_loss: 906364.3750\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 377026.9375 - val_loss: 908641.8125\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 374568.9375 - val_loss: 927420.1250\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 372023.4688 - val_loss: 925541.8125\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 370188.5938 - val_loss: 908676.3750\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 364081.1875 - val_loss: 911213.3125\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 374485.7188 - val_loss: 906748.1875\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 381927.8125 - val_loss: 897738.8125\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 373688.4688 - val_loss: 910556.8750\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 369073.8438 - val_loss: 919004.6250\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 382802.9688 - val_loss: 920511.8125\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 372419.6562 - val_loss: 904739.0000\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 359972.8438 - val_loss: 888251.1250\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 379451.5625 - val_loss: 896282.8750\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 357652.2812 - val_loss: 904721.6250\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 370374.8750 - val_loss: 897002.1875\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 372821.8750 - val_loss: 896130.3750\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 363740.7188 - val_loss: 911630.8750\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 373928.5000 - val_loss: 920100.1250\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 369401.4375 - val_loss: 914756.1250\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 362943.2188 - val_loss: 895589.1250\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 364648.4062 - val_loss: 880125.8750\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 359844.7812 - val_loss: 900365.6250\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 357363.0312 - val_loss: 917492.3750\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 362531.5000 - val_loss: 895531.0000\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 354491.5938 - val_loss: 887500.6250\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 353243.6875 - val_loss: 908179.6250\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 356256.4375 - val_loss: 908274.3750\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 363417.2812 - val_loss: 899419.3750\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 359327.2188 - val_loss: 900182.0000\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 348947.7812 - val_loss: 904166.8750\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 364745.7812 - val_loss: 912120.8750\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 366554.2500 - val_loss: 898651.3750\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 356970.1250 - val_loss: 885622.1875\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 344469.1562 - val_loss: 900042.1250\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 352440.0000 - val_loss: 911036.8125\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 354329.0312 - val_loss: 905033.1875\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 352698.1875 - val_loss: 900334.6250\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 344799.7812 - val_loss: 900012.8750\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 351654.5000 - val_loss: 893113.0000\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 366286.8438 - val_loss: 892658.6250\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 364884.1562 - val_loss: 889601.6250\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 356279.3750 - val_loss: 898456.0000\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 378926.5312 - val_loss: 894385.5000\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 366345.6562 - val_loss: 894623.3750\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 356201.7812 - val_loss: 907094.8125\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 366838.9375 - val_loss: 905489.1875\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 364322.9688 - val_loss: 893158.6875\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 360427.7812 - val_loss: 875599.1875\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 360836.9688 - val_loss: 871579.8750\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 341746.5625 - val_loss: 874479.3750\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 342818.6562 - val_loss: 887681.6875\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 369867.5938 - val_loss: 878565.6250\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 345703.3750 - val_loss: 879595.1875\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 345315.8125 - val_loss: 902089.1250\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 358169.0312 - val_loss: 897300.6250\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 353069.4375 - val_loss: 893386.3750\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 355231.4375 - val_loss: 911824.8750\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 364140.8125 - val_loss: 910673.1875\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 363718.9375 - val_loss: 901422.3125\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 366744.3750 - val_loss: 883838.3750\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 362716.5000 - val_loss: 883713.5000\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 360372.9688 - val_loss: 888552.3125\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 365307.8750 - val_loss: 887109.3750\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 364855.4688 - val_loss: 895133.3750\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 362000.4375 - val_loss: 896646.1875\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 370335.7812 - val_loss: 886355.8750\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 358672.3750 - val_loss: 878715.8750\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 349726.1250 - val_loss: 887143.3125\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 354210.9062 - val_loss: 893514.3750\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 372241.0625 - val_loss: 895788.8750\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 355670.3125 - val_loss: 897935.8750\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 371041.0625 - val_loss: 879593.8125\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 374507.9688 - val_loss: 864780.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 353069.8750 - val_loss: 891982.6250\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 353860.1250 - val_loss: 913163.8750\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 374752.1562 - val_loss: 904710.6250\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 373164.9375 - val_loss: 877364.1250\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 366420.6250 - val_loss: 866247.5000\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 356827.2188 - val_loss: 868995.0000\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 362058.3438 - val_loss: 887277.0000\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 375732.8750 - val_loss: 891674.6250\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 377866.6562 - val_loss: 887792.8750\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 352454.7500 - val_loss: 891347.3125\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 362106.6875 - val_loss: 889356.1250\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 365701.9688 - val_loss: 880653.6250\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 371555.2500 - val_loss: 877577.3750\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 374602.3438 - val_loss: 882745.1875\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 384451.0312 - val_loss: 883373.3750\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 371382.8438 - val_loss: 888752.8125\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 372040.2500 - val_loss: 894706.3750\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 372055.0938 - val_loss: 891430.8750\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 376223.3125 - val_loss: 887883.5000\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 376505.2188 - val_loss: 876725.6250\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 375070.7500 - val_loss: 881093.8750\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 352090.3750 - val_loss: 884477.6875\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 366972.5000 - val_loss: 879072.0000\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 392298.0000 - val_loss: 867573.1875\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 374318.4688 - val_loss: 877840.6875\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 365157.8125 - val_loss: 869378.1875\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 376775.8438 - val_loss: 863629.1250\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 387715.5000 - val_loss: 861150.8750\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 372665.8438 - val_loss: 862294.1875\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 383004.9688 - val_loss: 862435.6875\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 376141.3438 - val_loss: 880713.6875\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 372686.8125 - val_loss: 889762.8125\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 382343.0938 - val_loss: 901404.8750\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 370229.6250 - val_loss: 892736.8750\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 356796.9375 - val_loss: 879632.6875\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 379893.6250 - val_loss: 863910.1250\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 363007.8438 - val_loss: 865155.1250\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 354908.5000 - val_loss: 861547.3750\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 375171.4688 - val_loss: 854459.8750\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 374575.2500 - val_loss: 856958.8750\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 361614.6250 - val_loss: 882093.8125\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 356215.2188 - val_loss: 895327.3750\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 362523.5000 - val_loss: 882980.1250\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 358913.7500 - val_loss: 867092.8125\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 360799.2188 - val_loss: 871712.5000\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 352861.8125 - val_loss: 876758.3750\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 358092.6562 - val_loss: 862932.6250\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 359627.3125 - val_loss: 851806.0000\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 361978.8125 - val_loss: 863126.6250\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 357701.9375 - val_loss: 877769.3125\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 362207.8438 - val_loss: 880391.6250\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 359247.5938 - val_loss: 869795.3750\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 360327.9062 - val_loss: 873293.8125\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 367025.8750 - val_loss: 878547.3750\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 366754.5625 - val_loss: 862450.6875\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 364637.8438 - val_loss: 862375.3750\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 359754.3125 - val_loss: 872138.1875\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 372154.2812 - val_loss: 866750.8125\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 362330.2500 - val_loss: 875668.8125\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 369409.9688 - val_loss: 882505.3750\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 356994.5938 - val_loss: 876591.8750\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 356236.5938 - val_loss: 879255.3750\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 372503.5625 - val_loss: 872110.6875\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 376764.4062 - val_loss: 855618.8750\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 360565.4062 - val_loss: 850060.6250\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 354584.2812 - val_loss: 858357.6250\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 363233.7188 - val_loss: 871659.1250\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 362765.5312 - val_loss: 865472.6250\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 370471.9375 - val_loss: 869571.8125\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 365372.3438 - val_loss: 859452.6250\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 345618.8750 - val_loss: 865874.3750\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 359957.4375 - val_loss: 874861.0000\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 349853.1875 - val_loss: 876536.8125\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 339226.5625 - val_loss: 866163.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 340831.8125 - val_loss: 849580.1250\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 359419.4688 - val_loss: 841248.8750\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 348643.8438 - val_loss: 850633.6250\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 349230.2500 - val_loss: 857254.3750\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 346442.9062 - val_loss: 861260.6875\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 344910.0312 - val_loss: 867575.1875\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 346002.0938 - val_loss: 875538.3750\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 350484.7188 - val_loss: 869427.1250\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 332398.3438 - val_loss: 871768.3125\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 338457.6250 - val_loss: 864796.8750\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 338589.3438 - val_loss: 859894.0000\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 296ms/step - loss: 330674.9062 - val_loss: 863601.1875\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 346541.0312 - val_loss: 854796.8750\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 348570.6875 - val_loss: 850809.1875\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 330655.3438 - val_loss: 868985.6875\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 335873.7188 - val_loss: 874597.8125\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 353053.2500 - val_loss: 860571.1875\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 339094.3125 - val_loss: 843576.5000\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 327458.2500 - val_loss: 841104.6250\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 336611.4062 - val_loss: 850575.8125\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 331365.5000 - val_loss: 851572.6250\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 342851.3125 - val_loss: 840922.6875\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 343160.7500 - val_loss: 840959.8750\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 325270.7188 - val_loss: 852365.8750\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 333600.9062 - val_loss: 859489.1250\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 338244.4688 - val_loss: 849024.1250\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 333391.1562 - val_loss: 845034.3125\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 337306.7812 - val_loss: 857865.6250\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 343637.1562 - val_loss: 853919.8750\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 323184.1562 - val_loss: 853094.8125\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 344498.0312 - val_loss: 848978.0000\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 354877.3438 - val_loss: 858436.1250\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 342553.1250 - val_loss: 854312.8750\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 340249.3125 - val_loss: 848286.0000\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 333354.6562 - val_loss: 856672.6875\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 335645.5938 - val_loss: 842468.1875\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 342338.7500 - val_loss: 830241.5625\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 327953.4688 - val_loss: 835480.6250\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 329332.0312 - val_loss: 836193.1875\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 336946.1250 - val_loss: 844756.6250\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 335988.6875 - val_loss: 843925.0000\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 336197.2812 - val_loss: 854970.0000\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 334124.3750 - val_loss: 853544.8750\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 340596.9688 - val_loss: 855057.1875\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 341523.1875 - val_loss: 836772.3125\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 361037.7812 - val_loss: 836692.9375\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 344897.5938 - val_loss: 847384.6875\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 342171.8438 - val_loss: 855967.3125\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 344639.1562 - val_loss: 846543.8125\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 348481.4688 - val_loss: 835358.3125\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 352502.8125 - val_loss: 834490.9375\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 338947.0312 - val_loss: 842714.8750\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 336257.6875 - val_loss: 837347.8125\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 339335.3125 - val_loss: 841193.1875\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 347171.9062 - val_loss: 858591.3750\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 344127.5938 - val_loss: 863280.1250\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 334755.9062 - val_loss: 849070.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f14c06d040>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit model\n",
    "history = model.fit(X, y, epochs=500, validation_split=0.2, verbose=1)\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5f9b9953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.19940868 0.20252952 0.29516055 ... 0.39687823 1.54012951 0.22414441]\n",
      " [0.21158379 0.20645395 0.30114212 ... 0.62565062 2.51018054 0.55780805]\n",
      " [0.25608766 0.24391593 0.36907415 ... 0.59789517 2.38610806 0.39009885]\n",
      " ...\n",
      " [0.37512038 0.34286911 0.42992231 ... 0.7405342  1.0993287  0.38700633]\n",
      " [0.28964867 0.27203361 0.31547104 ... 0.55690654 1.09062576 0.36427905]\n",
      " [0.37237919 0.34448221 0.42569258 ... 0.79619109 1.25332278 0.55546484]]\n",
      "[[[0.32167327 0.2967602  0.34147733 ... 0.789797   1.5018106  0.6898142 ]\n",
      "  [0.36916387 0.33875683 0.3879845  ... 0.8775994  1.6572398  0.7505411 ]\n",
      "  [0.38256544 0.34923342 0.40308285 ... 0.888762   1.6507659  0.73369706]\n",
      "  ...\n",
      "  [0.4118432  0.34136438 0.41735554 ... 0.9357611  1.4244382  0.6611331 ]\n",
      "  [0.41521913 0.34165052 0.41863447 ... 0.9324986  1.3902617  0.6578481 ]\n",
      "  [0.41842812 0.34192264 0.4198503  ... 0.92939776 1.3577763  0.65472573]]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "x_test_scaled = dataset[-(n_steps_out+n_steps_in):-n_steps_out]\n",
    "print(x_test_scaled)\n",
    "x_test_scaled = x_test_scaled.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_test_scaled, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "12005fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.32167327 0.2967602  0.34147733 ... 0.789797   1.5018106  0.6898142 ]\n",
      " [0.36916387 0.33875683 0.3879845  ... 0.8775994  1.6572398  0.7505411 ]\n",
      " [0.38256544 0.34923342 0.40308285 ... 0.888762   1.6507659  0.73369706]\n",
      " ...\n",
      " [0.4118432  0.34136438 0.41735554 ... 0.9357611  1.4244382  0.6611331 ]\n",
      " [0.41521913 0.34165052 0.41863447 ... 0.9324986  1.3902617  0.6578481 ]\n",
      " [0.41842812 0.34192264 0.4198503  ... 0.92939776 1.3577763  0.65472573]]\n",
      "[[0.32167327 0.2967602  0.34147733 ... 0.789797   1.5018106  0.6898142 ]\n",
      " [0.36916387 0.33875683 0.3879845  ... 0.8775994  1.6572398  0.7505411 ]\n",
      " [0.38256544 0.34923342 0.40308285 ... 0.888762   1.6507659  0.73369706]\n",
      " ...\n",
      " [0.4118432  0.34136438 0.41735554 ... 0.9357611  1.4244382  0.6611331 ]\n",
      " [0.41521913 0.34165052 0.41863447 ... 0.9324986  1.3902617  0.6578481 ]\n",
      " [0.41842812 0.34192264 0.4198503  ... 0.92939776 1.3577763  0.65472573]]\n",
      "[[0.39812233 0.37206137 0.43753179 ... 0.97550461 1.64160132 0.67047578]\n",
      " [0.3626103  0.31876718 0.40187582 ... 1.51826678 2.24567499 0.96926892]\n",
      " [0.26376623 0.22110223 0.32058841 ... 1.23122559 2.11328992 0.75145063]\n",
      " ...\n",
      " [0.37375369 0.34499689 0.40026859 ... 1.20782415 1.77394841 0.81705893]\n",
      " [0.3336417  0.30050302 0.36040647 ... 1.1479989  1.64021404 0.75481252]\n",
      " [0.24217588 0.21514682 0.33592286 ... 0.76868481 1.48927726 0.54231719]]\n"
     ]
    }
   ],
   "source": [
    "yhat = yhat.reshape(yhat.shape[1],yhat.shape[2])\n",
    "print(yhat)\n",
    "# y_test = scaler.inverse_transform(yhat)\n",
    "print(yhat)\n",
    "print(dataset[-n_steps_out:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "678fecdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.17855854771327\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "mape = mean_absolute_percentage_error(yhat,dataset[-n_steps_out:])\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80c07f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.24112035 0.21626987 0.32411527 ... 1.12460705 2.12180164 0.74896713]\n",
      " [0.26463583 0.23384112 0.33724036 ... 1.29014463 2.54480154 0.85426393]\n",
      " [0.25328632 0.2454324  0.32881964 ... 0.91927311 2.19357749 0.71403381]\n",
      " ...\n",
      " [0.37375369 0.34499689 0.40026859 ... 1.20782415 1.77394841 0.81705893]\n",
      " [0.3336417  0.30050302 0.36040647 ... 1.1479989  1.64021404 0.75481252]\n",
      " [0.24217588 0.21514682 0.33592286 ... 0.76868481 1.48927726 0.54231719]]\n",
      "[[[0.33738723 0.3080175  0.35263312 ... 0.8210426  1.5802507  0.72892505]\n",
      "  [0.40918347 0.36887115 0.41791046 ... 0.95880735 1.8545866  0.8481622 ]\n",
      "  [0.4217725  0.37874633 0.4321081  ... 0.96940446 1.8487684  0.8325107 ]\n",
      "  ...\n",
      "  [0.49083063 0.4348647  0.49800223 ... 1.1498815  1.7565211  0.82200396]\n",
      "  [0.49402723 0.43513292 0.4992122  ... 1.1467867  1.7241287  0.8188921 ]\n",
      "  [0.49706337 0.43538564 0.50036067 ... 1.1438427  1.6933397  0.8159354 ]]]\n"
     ]
    }
   ],
   "source": [
    "x_input_scaled = dataset[-n_steps_in:]\n",
    "print(x_input_scaled)\n",
    "x_input_scaled = x_input_scaled.reshape((1, n_steps_in, n_features))\n",
    "yhat = model.predict(x_input_scaled, verbose=0)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1fc7e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33738723 0.3080175  0.35263312 ... 0.8210426  1.5802507  0.72892505]\n",
      " [0.40918347 0.36887115 0.41791046 ... 0.95880735 1.8545866  0.8481622 ]\n",
      " [0.4217725  0.37874633 0.4321081  ... 0.96940446 1.8487684  0.8325107 ]\n",
      " ...\n",
      " [0.49083063 0.4348647  0.49800223 ... 1.1498815  1.7565211  0.82200396]\n",
      " [0.49402723 0.43513292 0.4992122  ... 1.1467867  1.7241287  0.8188921 ]\n",
      " [0.49706337 0.43538564 0.50036067 ... 1.1438427  1.6933397  0.8159354 ]]\n"
     ]
    }
   ],
   "source": [
    "yhat = yhat.reshape(yhat.shape[1],yhat.shape[2])\n",
    "# y_pred = scaler.inverse_transform(yhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "82305cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 3915)\n"
     ]
    }
   ],
   "source": [
    "print(yhat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "85995ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(yhat)\n",
    "output.to_csv('submission_LSTM_new.csv')\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a61174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
